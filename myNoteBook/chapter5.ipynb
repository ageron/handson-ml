{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "关于这个向量机。如果把所有的特征，组成一个向量，然后组成一个向量空间。最后，用一个平面来区分这些向量。然后我们看到的就是投影。但是我没法证明，\n",
    "也不能用公式表述。\n",
    "\n",
    "然后本章，就是把这些不同的向量机给我展现一下。看下来，关键是几个变量\n",
    "\n",
    "- C\n",
    "- Kernel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('linear_svc',\n                 LinearSVC(C=1, class_weight=None, dual=True,\n                           fit_intercept=True, intercept_scaling=1,\n                           loss='hinge', max_iter=1000, multi_class='ovr',\n                           penalty='l2', random_state=None, tol=0.0001,\n                           verbose=0))],\n         verbose=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import  LinearSVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:,(2,3)]\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"linear_svc\",LinearSVC(C=1,loss=\"hinge\"))\n",
    "])\n",
    "\n",
    "svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "svm_clf.predict([[5.5,1.7]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Nonlinear SVM classification\n",
    "\n",
    "其实这里，我有点理解 polynomial feature的作用。\n",
    "简单的来说，就是你有一杯可乐。一杯牛奶。你单独喝，只有一种口味。但是你1/2的可乐和1/2的牛奶。1/3的可乐，2/3的可乐。就变成3种饮料。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/chandlersong/.conda/envs/MLBase/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('poly_features',\n                 PolynomialFeatures(degree=3, include_bias=True,\n                                    interaction_only=False, order='C')),\n                ('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('svm_clf',\n                 LinearSVC(C=10, class_weight=None, dual=True,\n                           fit_intercept=True, intercept_scaling=1,\n                           loss='hinge', max_iter=1000, multi_class='ovr',\n                           penalty='l2', random_state=None, tol=0.0001,\n                           verbose=0))],\n         verbose=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X,y = make_moons(n_samples=100,noise=0.15)\n",
    "ploynomial_svm_clf = Pipeline([\n",
    "    (\"poly_features\",PolynomialFeatures(degree=3)),\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"svm_clf\",LinearSVC(C=10,loss=\"hinge\"))\n",
    "])\n",
    "\n",
    "ploynomial_svm_clf.fit(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 10)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "ploynomial = PolynomialFeatures(degree=3)\n",
    "ploynomial.fit_transform(X,y).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 下面介绍两个常用的kernel。其他kernel用的不多。\n",
    "- 首先尝试用LinearSVC。这个快。\n",
    "\n",
    "### polynomial Kernel\n",
    "\n",
    "总结一下吧\n",
    "\n",
    "1. polynomial feature这种技术很NB。因为可以\"增加\" feature。但是对性能要求很高。\n",
    "2. 缺点是性能很糟糕。\n",
    "3. 这里面有一种核技术(kernel trick)获得收益的时候，不会有太大的性能损耗。\n",
    "\n",
    "然后用ploynomial的时候，如果overfitting，就减少degree。反之，则减少degree。\n",
    "\n",
    "cef0受高阶还是低阶函数影响。我真的不知道。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('svm_clf',\n                 SVC(C=5, break_ties=False, cache_size=200, class_weight=None,\n                     coef0=1, decision_function_shape='ovr', degree=3,\n                     gamma='scale', kernel='poly', max_iter=-1,\n                     probability=False, random_state=None, shrinking=True,\n                     tol=0.001, verbose=False))],\n         verbose=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "ploy_kernel_svm_clf = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"svm_clf\",SVC(kernel=\"poly\",degree=3,coef0=1,C=5))\n",
    "])\n",
    "\n",
    "ploy_kernel_svm_clf.fit(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gaussian RBF\n",
    "\n",
    "另一种处理方式。看那个公式，我已经没有感觉了。\n",
    "\n",
    "- 其实所有的计算，都是线性代数的做法。\n",
    "- 和ploy一样。他也有其kernel函数\n",
    "\n",
    "- gramma($\\gamma$)类似与上文中degree是一个作用。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('svm_clf',\n                 SVC(C=0.001, break_ties=False, cache_size=200,\n                     class_weight=None, coef0=0.0,\n                     decision_function_shape='ovr', degree=3, gamma=5,\n                     kernel='rbf', max_iter=-1, probability=False,\n                     random_state=None, shrinking=True, tol=0.001,\n                     verbose=False))],\n         verbose=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"svm_clf\",SVC(kernel=\"rbf\",gamma=5,C=0.001))\n",
    "])\n",
    "\n",
    "rbf_kernel_svm_clf.fit(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM Regression\n",
    "\n",
    "简单的来说，就是变换目标。使得定，精良在这个街道上面。\n",
    "\n",
    "## under hood\n",
    "\n",
    "前面看懂了。其实就是一个$Ax=b$的问题，然后求解了一个空间。而这个空间中来的斜率和第一章的街成反比\n",
    "\n",
    "但是有后面完全看不懂。找了一些资料。完全看不懂什么是什么。就是感觉是一个已知方程的优化问题。\n",
    "\n",
    "- [wiki上的说明](https://zh.wikipedia.org/wiki/%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92)\n",
    "- [一些资料](https://cbb1996.com/2019/07/20/3-convexop/)\n",
    "\n",
    "\n",
    "-  `convex quadratic optimization problems`\n",
    "-  `The dual problem`\n",
    "-  `kernelized SVM`\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}